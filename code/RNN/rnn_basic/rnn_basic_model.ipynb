{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d76d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../'*3\n",
    "RUN_DIR = BASE_DIR + 'code/CNN/ext_model/ext_model.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e4017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run {RUN_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76089cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnBasicModel(CnnExtModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad83da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_basic_alloc_rnn_layer(self, input_shape, hconfig):\n",
    "    \n",
    "    inseq = get_conf_param(hconfig, 'inseq', True)\n",
    "    outseq = get_conf_param(hconfig, 'outseq', True)\n",
    "    \n",
    "    if inseq:\n",
    "        timesteps1, timefeats = inpu_shape\n",
    "    else:\n",
    "        timesteps1 = get_conf_param(hconfig, 'timesteps') + 1\n",
    "        timefeats = np.prod(input_shape)\n",
    "        \n",
    "    recur_size = get_conf_param(hconfig, 'recur_size')\n",
    "    \n",
    "    ex_inp_dim = timefeats + recur_size\n",
    "    weight, bias = self.alloc_param_pair([ex_inp_dim, recur_size])\n",
    "    \n",
    "    if outseq:\n",
    "        output_shape = [timesteps1, recur_size]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        output_shape = [recur_size]\n",
    "    rnn_info = [inseq, outseq, timesteps1, timefeats, recur_size]\n",
    "    \n",
    "    return {'w':weight, 'b': bias, 'info':rnn_info}, output_shape\n",
    "\n",
    "\n",
    "RnnBasicModel.alloc_rnn_layer = rnn_basic_alloc_rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880ab66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_basic_forward_rnn_layer(self, x, hconfig, pm):\n",
    "    inseq, outseq, timesteps1, timefeats, recur_size = pm['info']\n",
    "    # inseq, outseq => bool\n",
    "    # timestep1 => 시간대 최대 길이\n",
    "    # timefeats => 시간대별 입력 벡터 길이\n",
    "    # recur_size => 순환벡터의 크기\n",
    "    mb_size = x.shape[0]\n",
    "    \n",
    "    # 입력 데이터 정보\n",
    "    \n",
    "    if inseq:\n",
    "        x_slices = x[:,1:,:].transpose([1,0,2])\n",
    "        lengths = x[:,0,0].astype(np.int32)\n",
    "        timesteps = np.max(lengths)\n",
    "    # 비시계열 입력 데이터 \n",
    "    else:\n",
    "        \n",
    "        x_slice = x\n",
    "        timesteps = timesteps1 - 1\n",
    "        lengths = [timesteps] * mb_size\n",
    "        \n",
    "    recurrent = np.zeros([mb_size, recur_size])\n",
    "    \n",
    "    output, aux_steps = [],[]\n",
    "    \n",
    "    for n in range(timesteps):\n",
    "        if inseq: x_slice = x_slices[n]\n",
    "        ex_inp = np.hstack([x_slice, recurrent])\n",
    "        affine = np.matmul(ex_inp, pm['w']) + pm['b']\n",
    "        recurrent = self.activate(affine, hconfig)\n",
    "        \n",
    "        outputs.append(recurrent)\n",
    "        aux_steps.append(ex_inp)\n",
    "        \n",
    "    if outseq:\n",
    "        \n",
    "        output = np.zeros([mb_size, timesteps1, recur_size])\n",
    "        output[:, 0, 0] = lengths\n",
    "        output[:,1:,:] = np.asarray(outputs).transpose([1,0,2])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        output = np.zeros([mb_size, recur_size])\n",
    "        for n in range(mb_size):\n",
    "            output[n] = outputs[lengths[n]-1[n]]\n",
    "            \n",
    "    return output, [x, lengths, timesteps, outputs, aux_steps]\n",
    "\n",
    "\n",
    "RnnBasicModel.forward_rnn_layer = rnn_basic_forward_rnn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caa7842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1,2,3],[4,5,6],[7,8,9]]\n",
    "np.hstack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7d8e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_basic_backprop_rnn_layer(self, G_y, hconfig, pm, aux):\n",
    "    inseq, outseq, timesteps1, timefeats, recur_size = pm['info']\n",
    "    x, lengths, timesteps, outputs, aux_steps = aux\n",
    "    \n",
    "    mb_size = x.shape[0]\n",
    "    \n",
    "    G_weight = np.zeros_like(pm['w'])\n",
    "    G_bais = np.zeros_like(pm['b'])\n",
    "    G_x = np.zeros(x.shape)\n",
    "    G_recurrent = np.zeros([mb_size, recur_size])\n",
    "    \n",
    "    if inseq: G_x[:,0,0] = lengths\n",
    "        \n",
    "    if outseq:\n",
    "        G_outputs = G_y[:,1:,:].transpose([1,0,2])\n",
    "    else:\n",
    "        G_outputs = np.zeros([timesteps, mb_size, recur_size])\n",
    "        \n",
    "        for n in range(mb_size):\n",
    "            G_outputs[lengths[n]-1,n,:] = G_y[n]\n",
    "            \n",
    "        for n in reversed(range(0, timesteps)):\n",
    "            G_recurrent += G_outputs[n]\n",
    "            \n",
    "            ex_inp = aux_steps[n]\n",
    "            \n",
    "            G_affine = self.activate_derv(G_recurrent, output[n], hconfig)\n",
    "            \n",
    "            g_affine_weight = ex_inp.transpose()\n",
    "            g_affine_input = pm['w'].transpose()\n",
    "            \n",
    "            G_weight += np.matmul(g_affine_weight, G_affine)\n",
    "            G_bias += np.sum(G_affine, axis = 0)\n",
    "            G_ex_inp = np.matmul(G_affine, g_affine_input)\n",
    "            \n",
    "            if inseq: G_x[:, n+1, :] = G_ex_inp[:, :timefeats]\n",
    "                \n",
    "            else : G_x[:,:] += G_ex_inp[:, :timefeats]\n",
    "                \n",
    "            G_recurrent = G_ex_inp[:, timefeats:]\n",
    "            \n",
    "        self.update_param(pm, 'w', G_weight)\n",
    "        self.update_param(pm, 'b', G_bias)\n",
    "        \n",
    "        return G_x\n",
    "    \n",
    "    \n",
    "    \n",
    "    RnnBasicModel.backprop_rnn_layer = rnn_basic_backprop_rnn_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c488326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
